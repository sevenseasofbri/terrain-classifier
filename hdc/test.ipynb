{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Dataset structure:\n",
    "audio/\n",
    "├── train\n",
    "│  ├── class\n",
    "│  │   ├── 1.wav\n",
    "│  │   ├── 2.wav\n",
    "│  │   ├── ...\n",
    "│  └── ...\n",
    "'''\n",
    "def load_dataset(type=\"train\"):\n",
    "    # Path to audio folder\n",
    "    audio_folder = \"audio/{}\".format(type)\n",
    "    # Extract all classes available by reading the subfolder names\n",
    "    classes = sorted(os.listdir(audio_folder))\n",
    "    # Extract all audio files available for each class as a separate list\n",
    "    audio_files = {}\n",
    "    for c in classes:\n",
    "        # Get all files in the class folder\n",
    "        audio_files[c] = sorted(glob(os.path.join(audio_folder, c, \"*.wav\")))\n",
    "\n",
    "    print(\"Classes: \", classes)\n",
    "    print(audio_files)\n",
    "    return audio_files, classes\n",
    "\n",
    "# load_dataset(\"train\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zcr(frame, frame_length):\n",
    "    \"\"\"Compute Zero Crossing Rate (ZCR)\"\"\"\n",
    "    # Count the number of times the signal changes sign\n",
    "    # zero_crossings = np.sum(np.abs(np.diff(np.sign(frame)))) / 2\n",
    "    # return zero_crossings / frame_length\n",
    "    return librosa.feature.zero_crossing_rate(frame, frame_length=frame_length)[0, 0]\n",
    "\n",
    "def rms(frame):\n",
    "    \"\"\"Compute Root Mean Square (RMS)\"\"\"\n",
    "    # RMS measures the average power of the signal\n",
    "    # return np.sqrt(np.sum(frame**2) / len(frame))\n",
    "    return np.sqrt(np.mean(frame**2))\n",
    "\n",
    "def temporal_entropy(frame):\n",
    "    \"\"\"Compute Temporal Entropy\"\"\"\n",
    "    # Temporal entropy measures the distribution of energy in the time domain\n",
    "    hist = np.histogram(frame, bins=8, range=(np.min(frame), np.max(frame)))[0]\n",
    "    prob = hist / np.sum(hist)\n",
    "    prob = prob[prob > 0]  # Avoid log(0)\n",
    "    return -np.sum(prob * np.log2(prob))\n",
    "\n",
    "def compute_fft(y, frame_length, hop_length):\n",
    "    \"\"\"Compute the Short-Time Fourier Transform (STFT) using NumPy.\"\"\"\n",
    "    # Frame-based processing\n",
    "    # frames = librosa.util.frame(y, frame_length=frame_length, hop_length=hop_length)\n",
    "    # window = np.hanning(frame_length)  # Apply a Hanning window\n",
    "    # fft_result = np.fft.rfft(frames * window[:, None], axis=0)  # Compute FFT\n",
    "    # return np.abs(fft_result)  # Return the magnitude spectrum\n",
    "    return librosa.stft(y, n_fft=frame_length, hop_length=hop_length, window='hann', center=False)\n",
    "\n",
    "def spectral_centroid(S, sr):\n",
    "    \"\"\"Compute Spectral Centroid\"\"\"\n",
    "    # Spectral centroid is the weighted mean of the frequencies\n",
    "    # freqs = np.fft.rfftfreq(S.shape[0] * 2 - 1, d=1/sr)\n",
    "    # magnitude = np.sum(S, axis=1)\n",
    "    # centroid = np.sum(freqs * magnitude) / np.sum(magnitude)\n",
    "    # return centroid\n",
    "    return librosa.feature.spectral_centroid(S=S, sr=sr)\n",
    "\n",
    "def spectral_rolloff(S, sr, roll_percent=0.85):\n",
    "    \"\"\"Compute Spectral Rolloff\"\"\"\n",
    "    # Spectral rolloff is the frequency below which a certain percentage of the total spectral energy is contained\n",
    "    # freqs = np.fft.rfftfreq(S.shape[0] * 2 - 1, d=1/sr)\n",
    "    # total_energy = np.sum(S)\n",
    "    # cumulative_energy = np.cumsum(S)\n",
    "    # rolloff_idx = np.where(cumulative_energy >= roll_percent * total_energy)[0]\n",
    "    # if len(rolloff_idx) == 0:  # Handle case where no index satisfies the condition\n",
    "    #     return freqs[-1]  # Return the highest frequency\n",
    "    # return freqs[rolloff_idx[0]]\n",
    "    # Using librosa's built-in function for simplicity\n",
    "    return librosa.feature.spectral_rolloff(S=S, sr=sr, roll_percent=roll_percent)\n",
    "\n",
    "def spectral_flatness(S):\n",
    "    \"\"\"Compute Spectral Flatness\"\"\"\n",
    "    # Spectral flatness is the ratio of the geometric mean to the arithmetic mean of the spectrum\n",
    "    # geometric_mean = np.exp(np.mean(np.log(S + 1e-10)))  # Add small value to avoid log(0)\n",
    "    # arithmetic_mean = np.mean(S)\n",
    "    # return geometric_mean / arithmetic_mean\n",
    "    return librosa.feature.spectral_flatness(S=S)\n",
    "\n",
    "def band_ratio(S, sr, frame_length):\n",
    "    \"\"\"Compute Band Energy Ratio (low vs mid frequencies)\"\"\"\n",
    "    # Band energy ratio compares the energy in different frequency bands\n",
    "    # freqs = np.fft.rfftfreq(frame_length, d=1/sr)\n",
    "    freqs = librosa.fft_frequencies(sr=sr, n_fft=frame_length)\n",
    "    low_band = (freqs >= 100) & (freqs < 1000)\n",
    "    mid_band = (freqs >= 1000) & (freqs < 4000)\n",
    "    low_energy = np.sum(S[low_band, :], axis=0)\n",
    "    mid_energy = np.sum(S[mid_band, :], axis=0)\n",
    "    return mid_energy / (low_energy + 1e-10)\n",
    "    # Add small value to avoid division by zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_audio_features(file_path, sr, frame_length=2048, hop_length=512):\n",
    "    \"\"\"Extract material sound features compatible with HDC requirements\"\"\"\n",
    "    \n",
    "    # Load audio with optimal parameters for material sounds\n",
    "    y, sr = librosa.load(file_path, sr=sr, duration=5.0)  # 16kHz sampling\n",
    "    \n",
    "    # Frame-based processing\n",
    "    frames = librosa.util.frame(y, frame_length=frame_length, hop_length=hop_length)\n",
    "    num_frames = frames.shape[1]\n",
    "    \n",
    "    # Initialize feature arrays with zeros\n",
    "    feature_names = ['zcr', 'rms', 'temporal_entropy', 'spectral_centroid', 'spectral_rolloff', 'spectral_flatness', 'band_ratio']\n",
    "    features = {name: np.zeros(num_frames) for name in feature_names}\n",
    "\n",
    "    # Time-domain features\n",
    "    for i in range(num_frames):\n",
    "        frame = frames[:, i]\n",
    "        features['zcr'][i] = zcr(frame, frame_length)\n",
    "        features['rms'][i] = rms(frame)\n",
    "        features['temporal_entropy'][i] = temporal_entropy(frame)\n",
    "\n",
    "    # Frequency-domain features\n",
    "    S = np.abs(librosa.stft(y, n_fft=frame_length, hop_length=hop_length))\n",
    "    features['spectral_centroid'] = spectral_centroid(S, sr)\n",
    "    features['spectral_rolloff'] = spectral_rolloff(S, sr)\n",
    "    features['spectral_flatness'] = spectral_flatness(S)\n",
    "\n",
    "    # Band energy ratio (low vs mid frequencies)\n",
    "    features['band_ratio'] = band_ratio(S, sr, frame_length)\n",
    "\n",
    "    # Aggregate statistics for HDC encoding\n",
    "    feature_vector = [\n",
    "        np.mean(features['zcr']), np.std(features['zcr']),\n",
    "        np.mean(features['rms']), np.max(features['rms']),\n",
    "        np.mean(features['temporal_entropy']),\n",
    "        np.mean(features['spectral_centroid']),\n",
    "        np.mean(features['spectral_rolloff']),\n",
    "        np.mean(features['spectral_flatness']),\n",
    "        np.mean(features['band_ratio'])\n",
    "    ]\n",
    "    \n",
    "    return feature_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# # Extract features for all audio files and encode them\n",
    "# dataset = []\n",
    "# labels = []\n",
    "\n",
    "# audio_files, classes = load_dataset(\"train\")\n",
    "\n",
    "\n",
    "# for label_idx, class_name in enumerate(classes):\n",
    "#     for file_path in audio_files[class_name]:\n",
    "#         # Extract features\n",
    "#         feature_vector = extract_audio_features(file_path, sr=8000)\n",
    "#         dataset.append(feature_vector)\n",
    "#         labels.append(label_idx)\n",
    "\n",
    "# # normailize the dataset where each column is a feature\n",
    "# dataset = np.array(dataset) \n",
    "# dataset = (dataset - np.min(dataset, axis=0)) / (np.max(dataset, axis=0) - np.min(dataset, axis=0))\n",
    "\n",
    "# # visualize the dataset in heatmap\n",
    "# plt.figure(figsize=(10, 8))\n",
    "# plt.imshow(dataset, aspect='auto', cmap='hot')\n",
    "# plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HDC operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Feature Setup ---\n",
    "feature_names = [\n",
    "    'zcr_mean', 'zcr_std', 'rms_mean', 'rms_max',\n",
    "    'entropy_mean', 'spectral_centroid_mean', 'spectral_rolloff_mean',\n",
    "    'spectral_flatness_mean', 'band_ratio_mean'\n",
    "]\n",
    "\n",
    "# Selectively chosen important feature pairs\n",
    "important_pairs = [\n",
    "    ('zcr_mean', 'entropy_mean'),\n",
    "    ('rms_mean', 'spectral_rolloff_mean'),\n",
    "    ('spectral_flatness_mean', 'spectral_centroid_mean'),\n",
    "    ('rms_max', 'band_ratio_mean')\n",
    "]\n",
    "\n",
    "# --- 1. Feature name codebook (via permutation) ---\n",
    "def generate_feature_codebook(feature_names, D):\n",
    "    base = np.random.randint(0, 2, D, dtype=np.uint8)\n",
    "    return {name: np.roll(base, i + 1) for i, name in enumerate(feature_names)}\n",
    "\n",
    "# --- 2. Pre-generate value level hypervectors ---\n",
    "def generate_value_level_hvs(levels, D):\n",
    "    level_hvs = []\n",
    "    for level in range(levels):\n",
    "        hv = np.zeros(D, dtype=np.uint8)\n",
    "        if level > 0:\n",
    "            n_bits = level * D // levels\n",
    "            indices = np.random.choice(D, n_bits, replace=False)\n",
    "            hv[indices] = 1\n",
    "        level_hvs.append(hv)\n",
    "    return level_hvs\n",
    "\n",
    "# --- 3. Map value to nearest level HV ---\n",
    "def get_value_hv(levels, value, level_hvs):\n",
    "    level = min(levels - 1, max(0, int(value * levels)))\n",
    "    return level_hvs[level]\n",
    "\n",
    "# --- 4. Encode single audio feature vector ---\n",
    "def encode_feature_vector(features, codebook, level_hvs, D, levels):\n",
    "    assert len(features) == len(codebook)\n",
    "    \n",
    "    feature_dict = dict(zip(codebook.keys(), features))\n",
    "    hvs = []\n",
    "\n",
    "    # Step 1: Encode individual features (key ⊙ value)\n",
    "    for name, value in feature_dict.items():\n",
    "        feat_hv = np.bitwise_xor(codebook[name], get_value_hv(levels, value, level_hvs))\n",
    "        hvs.append(feat_hv.astype(np.int16))\n",
    "\n",
    "    # Step 2: Encode selected feature-pair interactions (bound pair HVs)\n",
    "    for f1, f2 in important_pairs:\n",
    "        hv1 = np.bitwise_xor(codebook[f1], get_value_hv(levels, feature_dict[f1], level_hvs))\n",
    "        hv2 = np.bitwise_xor(codebook[f2], get_value_hv(levels, feature_dict[f2], level_hvs))\n",
    "        pair_hv = np.bitwise_xor(hv1, hv2)\n",
    "        hvs.append(pair_hv.astype(np.int16))\n",
    "\n",
    "    # Optional: visualize before bundling\n",
    "    # plt.figure(figsize=(10, 8))\n",
    "    # plt.imshow(hvs, aspect='auto', cmap='hot', vmin=0, vmax=1)\n",
    "    # plt.colorbar()\n",
    "    \n",
    "    # Step 3: Final bundling (majority vote)\n",
    "    hvs = np.array(hvs)\n",
    "    sum_hv = np.sum(hvs, axis=0)\n",
    "    threshold = len(hvs) // 2\n",
    "    final_hv = (sum_hv > threshold).astype(np.uint8)\n",
    "    # print(sum_hv.shape, hvs.shape, len(hvs),final_hv.shape)\n",
    "\n",
    "    return final_hv\n",
    "\n",
    "#######\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# make array of all values in the codebook\n",
    "codebook_values = np.array(list(codebook.values()))\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.imshow(vectors, aspect='auto', cmap=plt.cm.gray) #, vmin=0, vmax=1)\n",
    "plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_hd_classifier(dataset, labels, codebook, level_hvs, D, levels, epochs):\n",
    "    \"\"\"\n",
    "    dataset: list or np.array of normalized feature vectors (N x 9)\n",
    "    labels: list or np.array of corresponding class labels (N)\n",
    "    codebook: feature-name -> HVs (symbolic keys of 9 features)\n",
    "    level_hvs: list of pre-generated value level HVs\n",
    "    \"\"\"\n",
    "\n",
    "    dataset = np.copy(dataset)\n",
    "    labels = np.copy(labels)\n",
    "\n",
    "    num_classes = len(np.unique(labels))\n",
    "    real_class_hvs = np.zeros((num_classes, D), dtype=np.int16)\n",
    "\n",
    "    N = len(dataset)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for i in range(N):\n",
    "            query_hv = dataset[i]\n",
    "            y_true = labels[i]\n",
    "\n",
    "            # Binarize class HVs\n",
    "            bin_class_hvs = (real_class_hvs >= 0).astype(np.uint8)\n",
    "\n",
    "            # Predict using Hamming distance\n",
    "            predictions = np.sum(query_hv != bin_class_hvs, axis=1)\n",
    "            y_pred = np.argmin(predictions)\n",
    "\n",
    "            # OnlineHD-style update\n",
    "            if y_pred != y_true:\n",
    "                real_class_hvs[y_true] += query_hv\n",
    "                real_class_hvs[y_pred] -= query_hv\n",
    "\n",
    "        # Shuffle\n",
    "        indices = np.random.permutation(N)\n",
    "        dataset = dataset[indices]\n",
    "        labels = labels[indices]\n",
    "\n",
    "    final_class_hvs = np.zeros((num_classes, D), dtype=np.int16)\n",
    "    final_class_hvs = (real_class_hvs >= 0).astype(np.uint8)\n",
    "    return final_class_hvs\n",
    "\n",
    "def predict_hd(query_hv, class_hvs):\n",
    "    \"\"\"\n",
    "    Predict label for a query hypervector using Hamming distance.\n",
    "    \"\"\"\n",
    "    distances = [np.sum(query_hv != class_hv) for class_hv in class_hvs]\n",
    "    return np.argmin(distances)\n",
    "\n",
    "def evaluate_hd(vectors, labels, class_hvs):\n",
    "    correct = 0\n",
    "    for query_hv, y_true in zip(vectors, labels, strict=True):\n",
    "\n",
    "        # query_hv = encode_feature_vector(x, codebook, level_hvs, D, levels)\n",
    "\n",
    "        y_pred = predict_hd(query_hv, class_hvs)\n",
    "        if y_pred == y_true:\n",
    "            correct += 1\n",
    "        # else:\n",
    "            # print(f\"Predicted: {y_pred}, True: {y_true}\")\n",
    "    return correct / len(labels)\n",
    "\n",
    "# def evaluate_hd(dataset, labels, label_to_id, id_to_label, class_hvs, codebook, level_hvs, D, levels):\n",
    "#     correct = 0\n",
    "#     for x, y_true in zip(dataset, labels):\n",
    "#         query_hv = encode_feature_vector(x, codebook, level_hvs, D, levels)\n",
    "#         y_pred = predict_hd(query_hv, class_hvs)\n",
    "#         if y_pred == y_true:\n",
    "#             correct += 1\n",
    "#         else:\n",
    "#             print(f\"Predicted: {y_pred}, True: {y_true}\")\n",
    "#     return correct / len(labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes:  ['bell', 'glass', 'saw']\n",
      "{'bell': ['audio/train/bell/1.wav', 'audio/train/bell/2.wav', 'audio/train/bell/3.wav', 'audio/train/bell/4.wav'], 'glass': ['audio/train/glass/1.wav', 'audio/train/glass/2.wav', 'audio/train/glass/3.wav', 'audio/train/glass/4.wav'], 'saw': ['audio/train/saw/1.wav', 'audio/train/saw/2.wav', 'audio/train/saw/3.wav', 'audio/train/saw/4.wav']}\n",
      "1: Training accuracy: 58.33%\n",
      "2: Training accuracy: 91.67%\n",
      "3: Training accuracy: 100.00%\n",
      "4: Training accuracy: 100.00%\n",
      "5: Training accuracy: 100.00%\n",
      "6: Training accuracy: 100.00%\n",
      "7: Training accuracy: 100.00%\n",
      "8: Training accuracy: 100.00%\n",
      "9: Training accuracy: 100.00%\n",
      "10: Training accuracy: 100.00%\n",
      "11: Training accuracy: 100.00%\n",
      "12: Training accuracy: 100.00%\n",
      "13: Training accuracy: 100.00%\n",
      "14: Training accuracy: 100.00%\n",
      "15: Training accuracy: 100.00%\n",
      "16: Training accuracy: 100.00%\n",
      "17: Training accuracy: 100.00%\n",
      "18: Training accuracy: 100.00%\n",
      "19: Training accuracy: 100.00%\n",
      "20: Training accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# --- Main execution ---\n",
    "\n",
    "# Load dataset\n",
    "dataset = [] # audio features\n",
    "labels = [] # class ids\n",
    "\n",
    "audio_files, classes = load_dataset(\"train\")\n",
    "\n",
    "# Prepare a dictionary of labels and their IDs\n",
    "label_to_id = {class_name: idx for idx, class_name in enumerate(classes)}\n",
    "id_to_label = {idx: class_name for class_name, idx in label_to_id.items()}\n",
    "\n",
    "# Extract features\n",
    "for _, class_name in enumerate(classes):\n",
    "    for file_path in audio_files[class_name]:\n",
    "        features = extract_audio_features(file_path, sr=8000)\n",
    "        dataset.append(features)\n",
    "        labels.append(label_to_id[class_name])\n",
    "\n",
    "\n",
    "# Normalize feature-wise (0–1 scaling)\n",
    "dataset = np.array(dataset)\n",
    "dataset = (dataset - dataset.min(axis=0)) / (dataset.max(axis=0) - dataset.min(axis=0))\n",
    "\n",
    "# generate codebooks\n",
    "D = 10000  # Hypervector dimensionality\n",
    "LEVELS = 256 # quantization levels\n",
    "np.random.seed(42)\n",
    "codebook = generate_feature_codebook(feature_names, D)\n",
    "value_level_hvs = generate_value_level_hvs(LEVELS, D)\n",
    "\n",
    "vectors = [] # encode dataset vectors\n",
    "\n",
    "for features in dataset:\n",
    "    encoded_hv = encode_feature_vector(features, codebook, value_level_hvs, D, LEVELS)\n",
    "    vectors.append(encoded_hv)\n",
    "\n",
    "vectors = np.array(vectors)\n",
    "labels = np.array(labels)\n",
    "\n",
    "for i in range(20):\n",
    "    # train the classifier\n",
    "    class_hvs = train_hd_classifier(vectors, labels, codebook, value_level_hvs, D, LEVELS, epochs=i+1)\n",
    "\n",
    "    # # Save the trained model\n",
    "    np.save(\"class_hvs.npy\", class_hvs) # save class hypervectors\n",
    "    np.save(\"codebook.npy\", codebook) # save codebook\n",
    "    np.save(\"value_level_hvs.npy\", value_level_hvs) # save value level hypervectors\n",
    "    np.save(\"label_to_id.npy\", label_to_id) # save label_to_id mapping\n",
    "\n",
    "    acc = evaluate_hd(vectors, labels, class_hvs)\n",
    "    print(f\"{i+1}: Training accuracy: {acc * 100:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes:  ['bell', 'glass', 'saw']\n",
      "{'bell': ['audio/test/bell/1.wav'], 'glass': ['audio/test/glass/1.wav'], 'saw': ['audio/test/saw/1.wav']}\n",
      "Testing accuracy: 66.67%\n"
     ]
    }
   ],
   "source": [
    "# --- Main execution ---\n",
    "\n",
    "# Load dataset\n",
    "dataset = [] # audio features\n",
    "labels = [] # class ids\n",
    "\n",
    "audio_files, classes = load_dataset(\"test\")\n",
    "\n",
    "# Prepare a dictionary of labels and their IDs\n",
    "label_to_id = np.load(\"label_to_id.npy\", allow_pickle=True).item()\n",
    "\n",
    "# Extract features\n",
    "for label_idx, class_name in enumerate(classes):\n",
    "    for file_path in audio_files[class_name]:\n",
    "        features = extract_audio_features(file_path, sr=8000)\n",
    "        dataset.append(features)\n",
    "        labels.append(label_to_id[class_name])\n",
    "\n",
    "\n",
    "# Normalize feature-wise (0–1 scaling)\n",
    "dataset = np.array(dataset)\n",
    "dataset = (dataset - dataset.min(axis=0)) / (dataset.max(axis=0) - dataset.min(axis=0))\n",
    "\n",
    "# generate codebooks\n",
    "D = 10000  # Hypervector dimensionality\n",
    "LEVELS = 256 # quantization levels\n",
    "np.random.seed(42)\n",
    "codebook = np.load(\"codebook.npy\", allow_pickle=True).item()\n",
    "value_level_hvs = np.load(\"value_level_hvs.npy\", allow_pickle=True)\n",
    "\n",
    "vectors = [] # encode dataset vectors\n",
    "\n",
    "for features in dataset:\n",
    "    encoded_hv = encode_feature_vector(features, codebook, value_level_hvs, D, LEVELS)\n",
    "    vectors.append(encoded_hv)\n",
    "\n",
    "vectors = np.array(vectors)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# train the trained class hypervectors\n",
    "class_hvs = np.load(\"class_hvs.npy\", allow_pickle=True)\n",
    "\n",
    "# Evaluate training performance\n",
    "acc = evaluate_hd(vectors, labels, class_hvs)\n",
    "print(f\"Testing accuracy: {acc * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export model weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HDC operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query HV is compared to all the class HVs in the item memory using Hamming distance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
